{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport seaborn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\nseaborn.set(style='whitegrid'); seaborn.set_context('talk')\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nfrom sklearn.datasets import load_iris\niris_data = load_iris()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:51.825407Z","iopub.execute_input":"2022-01-23T13:47:51.825970Z","iopub.status.idle":"2022-01-23T13:47:53.567640Z","shell.execute_reply.started":"2022-01-23T13:47:51.825914Z","shell.execute_reply":"2022-01-23T13:47:53.566656Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print(iris_data['DESCR'])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:53.570616Z","iopub.execute_input":"2022-01-23T13:47:53.571146Z","iopub.status.idle":"2022-01-23T13:47:53.578453Z","shell.execute_reply.started":"2022-01-23T13:47:53.571093Z","shell.execute_reply":"2022-01-23T13:47:53.576457Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"n_samples, n_features = iris_data.data.shape\n\nplt.subplot(1, 2, 1)\nscatter_plot = plt.scatter(iris_data.data[:,0], iris_data.data[:,1], alpha=0.5, \n                           c=iris_data.target) \nplt.colorbar(ticks=([0, 1, 2]))\nplt.title('Sepal Sample')\n\nplt.subplot(1, 2, 2)\nscatter_plot_2 = plt.scatter(iris_data.data[:,2], iris_data.data[:,3], alpha=0.5, \n                           c=iris_data.target)\nplt.colorbar(ticks=([0, 1, 2]))\nplt.title('Petal Sample')","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:53.579819Z","iopub.execute_input":"2022-01-23T13:47:53.580102Z","iopub.status.idle":"2022-01-23T13:47:54.099216Z","shell.execute_reply.started":"2022-01-23T13:47:53.580049Z","shell.execute_reply":"2022-01-23T13:47:54.097563Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas\nfrom pandas.plotting import scatter_matrix\n\n\ndataset = pandas.read_csv('../input/iris/Iris.csv')\nscatter_matrix(dataset, alpha=0.5, figsize=(20, 20))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:54.100654Z","iopub.execute_input":"2022-01-23T13:47:54.100899Z","iopub.status.idle":"2022-01-23T13:47:56.539753Z","shell.execute_reply.started":"2022-01-23T13:47:54.100854Z","shell.execute_reply":"2022-01-23T13:47:56.539151Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset.hist(alpha=0.5, figsize=(20, 20), color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:56.542230Z","iopub.execute_input":"2022-01-23T13:47:56.542549Z","iopub.status.idle":"2022-01-23T13:47:58.146497Z","shell.execute_reply.started":"2022-01-23T13:47:56.542505Z","shell.execute_reply":"2022-01-23T13:47:58.145603Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset.plot(subplots=True, figsize=(10, 10), sharex=False, sharey=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:58.147914Z","iopub.execute_input":"2022-01-23T13:47:58.148251Z","iopub.status.idle":"2022-01-23T13:47:59.136524Z","shell.execute_reply.started":"2022-01-23T13:47:58.148191Z","shell.execute_reply":"2022-01-23T13:47:59.135971Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"random.seed(123)\n\ndef separate_data():\n    A = iris_dataset[0:40]\n    tA = iris_dataset[40:50]\n    B = iris_dataset[50:90]\n    tB = iris_dataset[90:100]\n    C = iris_dataset[100:140]\n    tC = iris_dataset[140:150]\n    train = np.concatenate((A,B,C))\n    test =  np.concatenate((tA,tB,tC))\n    return train,test\n\ntrain_porcent = 80 # Porcent Training \ntest_porcent = 20 # Porcent Test\niris_dataset = np.column_stack((iris_data.data,iris_data.target.T)) #Join X and Y\niris_dataset = list(iris_dataset)\nrandom.shuffle(iris_dataset)\n\nFiletrain, Filetest = separate_data()\n\ntrain_X = np.array([i[:4] for i in Filetrain])\ntrain_y = np.array([i[4] for i in Filetrain])\ntest_X = np.array([i[:4] for i in Filetest])\ntest_y = np.array([i[4] for i in Filetest])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.137535Z","iopub.execute_input":"2022-01-23T13:47:59.137841Z","iopub.status.idle":"2022-01-23T13:47:59.151432Z","shell.execute_reply.started":"2022-01-23T13:47:59.137806Z","shell.execute_reply":"2022-01-23T13:47:59.150285Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\n\nplt.subplot(1, 2, 1)\nplt.scatter(train_X[:,0],train_X[:,1],c=train_y,cmap=cm.viridis)\nplt.xlabel(iris_data.feature_names[0])\nplt.ylabel(iris_data.feature_names[1])\n\nplt.subplot(1, 2, 2)\nplt.scatter(train_X[:,2],train_X[:,3],c=train_y,cmap=cm.viridis)\nplt.xlabel(iris_data.feature_names[2])\nplt.ylabel(iris_data.feature_names[3])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.153117Z","iopub.execute_input":"2022-01-23T13:47:59.153386Z","iopub.status.idle":"2022-01-23T13:47:59.525970Z","shell.execute_reply.started":"2022-01-23T13:47:59.153328Z","shell.execute_reply":"2022-01-23T13:47:59.524886Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plt.subplot(1, 2, 1)\nplt.scatter(test_X[:,0],test_X[:,1],c=test_y,cmap=cm.viridis)\nplt.xlabel(iris_data.feature_names[0])\nplt.ylabel(iris_data.feature_names[1]) \n\nplt.subplot(1, 2, 2)\nplt.scatter(test_X[:,2],test_X[:,3],c=test_y,cmap=cm.viridis)\nplt.xlabel(iris_data.feature_names[2])\nplt.ylabel(iris_data.feature_names[3])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.527313Z","iopub.execute_input":"2022-01-23T13:47:59.527561Z","iopub.status.idle":"2022-01-23T13:47:59.847674Z","shell.execute_reply.started":"2022-01-23T13:47:59.527511Z","shell.execute_reply":"2022-01-23T13:47:59.847122Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"x = 0 \nativation = {(lambda x: 1/(1 + np.exp(-x)))}\nderiv = {(lambda x: x*(1-x))}","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.848699Z","iopub.execute_input":"2022-01-23T13:47:59.849014Z","iopub.status.idle":"2022-01-23T13:47:59.855346Z","shell.execute_reply.started":"2022-01-23T13:47:59.848978Z","shell.execute_reply":"2022-01-23T13:47:59.854064Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"activation_tang = {(lambda x: np.tanh(x))}\nderiv_tang = {(lambda x: 1-x**2)}\n  ","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.856963Z","iopub.execute_input":"2022-01-23T13:47:59.857274Z","iopub.status.idle":"2022-01-23T13:47:59.869660Z","shell.execute_reply.started":"2022-01-23T13:47:59.857212Z","shell.execute_reply":"2022-01-23T13:47:59.868995Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"activation_ReLU = {(lambda x: x*(x > 0))}\nderiv_ReLU = {(lambda x: 1 * (x>0))}","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.870732Z","iopub.execute_input":"2022-01-23T13:47:59.871061Z","iopub.status.idle":"2022-01-23T13:47:59.882492Z","shell.execute_reply.started":"2022-01-23T13:47:59.871009Z","shell.execute_reply":"2022-01-23T13:47:59.881239Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\nimport random\n\nclass MultiLayerPerceptron(BaseEstimator, ClassifierMixin): \n    def __init__(self, params=None):     \n        if (params == None):\n            self.inputLayer = 4                        # Input Layer\n            self.hiddenLayer = 5                       # Hidden Layer\n            self.outputLayer = 3                       # Outpuy Layer\n            self.learningRate = 0.005                  # Learning rate\n            self.max_epochs = 600                      # Epochs\n            self.iasHiddenValue = -1                   # Bias HiddenLayer\n            self.BiasOutputValue = -1                  # Bias OutputLayer\n            self.activation = self.ativacao['sigmoid'] # Activation function\n            self.deriv = self.derivada['sigmoid']\n        else:\n            self.inputLayer = params['InputLayer']\n            self.hiddenLayer = params['HiddenLayer']\n            self.OutputLayer = params['OutputLayer']\n            self.learningRate = params['LearningRate']\n            self.max_epochs = params['Epocas']\n            self.BiasHiddenValue = params['BiasHiddenValue']\n            self.BiasOutputValue = params['BiasOutputValue']\n            self.activation = self.ativacao[params['ActivationFunction']]\n            self.deriv = self.derivada[params['ActivationFunction']]\n        \n        'Starting Bias and Weights'\n        self.WEIGHT_hidden = self.starting_weights(self.hiddenLayer, self.inputLayer)\n        self.WEIGHT_output = self.starting_weights(self.OutputLayer, self.hiddenLayer)\n        self.BIAS_hidden = np.array([self.BiasHiddenValue for i in range(self.hiddenLayer)])\n        self.BIAS_output = np.array([self.BiasOutputValue for i in range(self.OutputLayer)])\n        self.classes_number = 3 \n        \n    pass\n    \n    def starting_weights(self, x, y):\n        return [[2  * random.random() - 1 for i in range(x)] for j in range(y)]\n\n    ativacao = {\n         'sigmoid': (lambda x: 1/(1 + np.exp(-x))),\n            'tanh': (lambda x: np.tanh(x)),\n            'Relu': (lambda x: x*(x > 0)),\n               }\n    derivada = {\n         'sigmoid': (lambda x: x*(1-x)),\n            'tanh': (lambda x: 1-x**2),\n            'Relu': (lambda x: 1 * (x>0))\n               }\n \n    def Backpropagation_Algorithm(self, x):\n        DELTA_output = []\n        'Stage 1 - Error: OutputLayer'\n        ERROR_output = self.output - self.OUTPUT_L2\n        DELTA_output = ((-1)*(ERROR_output) * self.deriv(self.OUTPUT_L2))\n        \n        arrayStore = []\n        'Stage 2 - Update weights OutputLayer and HiddenLayer'\n        for i in range(self.hiddenLayer):\n            for j in range(self.OutputLayer):\n                self.WEIGHT_output[i][j] -= (self.learningRate * (DELTA_output[j] * self.OUTPUT_L1[i]))\n                self.BIAS_output[j] -= (self.learningRate * DELTA_output[j])\n      \n        'Stage 3 - Error: HiddenLayer'\n        delta_hidden = np.matmul(self.WEIGHT_output, DELTA_output)* self.deriv(self.OUTPUT_L1)\n \n        'Stage 4 - Update weights HiddenLayer and InputLayer(x)'\n        for i in range(self.OutputLayer):\n            for j in range(self.hiddenLayer):\n                self.WEIGHT_hidden[i][j] -= (self.learningRate * (delta_hidden[j] * x[i]))\n                self.BIAS_hidden[j] -= (self.learningRate * delta_hidden[j])\n                \n    def show_err_graphic(self,v_erro,v_epoca):\n        plt.figure(figsize=(9,4))\n        plt.plot(v_epoca, v_erro, \"m-\",color=\"b\", marker=11)\n        plt.xlabel(\"Number of Epochs\")\n        plt.ylabel(\"Squared error (MSE) \");\n        plt.title(\"Error Minimization\")\n        plt.show()\n\n    def predict(self, X, y):\n        'Returns the predictions for every element of X'\n        my_predictions = []\n        'Forward Propagation'\n        forward = np.matmul(X,self.WEIGHT_hidden) + self.BIAS_hidden\n        forward = np.matmul(forward, self.WEIGHT_output) + self.BIAS_output\n                                 \n        for i in forward:\n            my_predictions.append(max(enumerate(i), key=lambda x:x[1])[0])\n            \n        array_score = []\n        for i in range(len(my_predictions)):\n            if my_predictions[i] == 0: \n                array_score.append([i, 'Iris-setosa', my_predictions[i], y[i]])\n            elif my_predictions[i] == 1:\n                 array_score.append([i, 'Iris-versicolour', my_predictions[i], y[i]])\n            elif my_predictions[i] == 2:\n                 array_score.append([i, 'Iris-virginica', my_predictions[i], y[i]])\n                    \n        dataframe = pd.DataFrame(array_score, columns=['_id', 'class', 'output', 'hoped_output'])\n        return my_predictions, dataframe\n\n    def fit(self, X, y):  \n        count_epoch = 1\n        total_error = 0\n        n = len(X); \n        epoch_array = []\n        error_array = []\n        W0 = []\n        W1 = []\n        while(count_epoch <= self.max_epochs):\n            for idx,inputs in enumerate(X): \n                self.output = np.zeros(self.classes_number)\n                'Stage 1 - (Forward Propagation)'\n                self.OUTPUT_L1 = self.activation((np.dot(inputs, self.WEIGHT_hidden) + self.BIAS_hidden.T))\n                self.OUTPUT_L2 = self.activation((np.dot(self.OUTPUT_L1, self.WEIGHT_output) + self.BIAS_output.T))\n                'Stage 2 - One-Hot-Encoding'\n                if(y[idx] == 0): \n                    self.output = np.array([1,0,0]) #Class1 {1,0,0}\n                elif(y[idx] == 1):\n                    self.output = np.array([0,1,0]) #Class2 {0,1,0}\n                elif(y[idx] == 2):\n                    self.output = np.array([0,0,1]) #Class3 {0,0,1}\n                \n                square_error = 0\n                for i in range(self.OutputLayer):\n                    erro = (self.output[i] - self.OUTPUT_L2[i])**2\n                    square_error = (square_error + (0.05 * erro))\n                    total_error = total_error + square_error\n         \n                'Backpropagation : Update Weights'\n                self.Backpropagation_Algorithm(inputs)\n                \n            total_error = (total_error / n)\n            if((count_epoch % 50 == 0)or(count_epoch == 1)):\n                print(\"Epoch \", count_epoch, \"- Total Error: \",total_error)\n                error_array.append(total_error)\n                epoch_array.append(count_epoch)\n                \n            W0.append(self.WEIGHT_hidden)\n            W1.append(self.WEIGHT_output)\n             \n                \n            count_epoch += 1\n        self.show_err_graphic(error_array,epoch_array)\n        \n        plt.plot(W0[0])\n        plt.title('Weight Hidden update during training')\n        plt.legend(['neuron1', 'neuron2', 'neuron3', 'neuron4', 'neuron5'])\n        plt.ylabel('Value Weight')\n        plt.show()\n        \n        plt.plot(W1[0])\n        plt.title('Weight Output update during training')\n        plt.legend(['neuron1', 'neuron2', 'neuron3'])\n        plt.ylabel('Value Weight')\n        plt.show()\n\n        return self","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.884242Z","iopub.execute_input":"2022-01-23T13:47:59.884598Z","iopub.status.idle":"2022-01-23T13:47:59.943063Z","shell.execute_reply.started":"2022-01-23T13:47:59.884562Z","shell.execute_reply":"2022-01-23T13:47:59.942429Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def show_test():\n    ep1 = [0,100,200,300,400,500,600,700,800,900,1000,1500,2000]\n    h_5 = [0,60,70,70,83.3,93.3,96.7,86.7,86.7,76.7,73.3,66.7,66.7]\n    h_4 = [0,40,70,63.3,66.7,70,70,70,70,66.7,66.7,43.3,33.3]\n    h_3 = [0,46.7,76.7,80,76.7,76.7,76.6,73.3,73.3,73.3,73.3,76.7,76.7]\n    plt.figure(figsize=(10,4))\n    l1, = plt.plot(ep1, h_3, \"--\",color='b',label=\"node-3\", marker=11)\n    l2, = plt.plot(ep1, h_4, \"--\",color='g',label=\"node-4\", marker=8)\n    l3, = plt.plot(ep1, h_5, \"--\",color='r',label=\"node-5\", marker=5)\n    plt.legend(handles=[l1,l2,l3], loc=1)\n    plt.xlabel(\"number of Epochs\")\n    plt.ylabel(\"% Hits\")\n    plt.title(\"Number of Hidden Layers - Performance\")\n    \n    ep2 = [0,100,200,300,400,500,600,700]\n    tanh = [0.18,0.027,0.025,0.022,0.0068,0.0060,0.0057,0.00561]\n    sigm = [0.185,0.0897,0.060,0.0396,0.0343,0.0314,0.0296,0.0281]\n    Relu = [0.185,0.05141,0.05130,0.05127,0.05124,0.05123,0.05122,0.05121]\n    plt.figure(figsize=(10,4))\n    l1 , = plt.plot(ep2, tanh, \"--\",color='b',label=\"Hyperbolic Tangent\",marker=11)\n    l2 , = plt.plot(ep2, sigm, \"--\",color='g',label=\"Sigmoide\", marker=8)\n    l3 , = plt.plot(ep2, Relu, \"--\",color='r',label=\"ReLu\", marker=5)\n    plt.legend(handles=[l1,l2,l3], loc=1)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Error\")\n    plt.title(\"Activation Functions - Performance\")\n    \n    fig, ax = plt.subplots()\n    names = [\"Hyperbolic Tangent\",\"Sigmoide\",\"ReLU\"]\n    x1 = [2.0,4.0,6.0]\n    plt.bar(x1[0], 53.4,0.4,color='b')\n    plt.bar(x1[1], 96.7,0.4,color='g')\n    plt.bar(x1[2], 33.2,0.4,color='r')\n    plt.xticks(x1,names)\n    plt.ylabel('% Hits')\n    plt.title('Hits - Activation Functions')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.944108Z","iopub.execute_input":"2022-01-23T13:47:59.944429Z","iopub.status.idle":"2022-01-23T13:47:59.968785Z","shell.execute_reply.started":"2022-01-23T13:47:59.944381Z","shell.execute_reply":"2022-01-23T13:47:59.967678Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"show_test()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:47:59.969936Z","iopub.execute_input":"2022-01-23T13:47:59.970209Z","iopub.status.idle":"2022-01-23T13:48:00.693930Z","shell.execute_reply.started":"2022-01-23T13:47:59.970153Z","shell.execute_reply":"2022-01-23T13:48:00.692419Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dictionary = {'InputLayer':4, 'HiddenLayer':5, 'OutputLayer':3,\n              'Epocas':700, 'LearningRate':0.005,'BiasHiddenValue':-1, \n              'BiasOutputValue':-1, 'ActivationFunction':'sigmoid'}\n\nPerceptron = MultiLayerPerceptron(dictionary)\nPerceptron.fit(train_X,train_y)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:48:00.695969Z","iopub.execute_input":"2022-01-23T13:48:00.696442Z","iopub.status.idle":"2022-01-23T13:48:25.952276Z","shell.execute_reply.started":"2022-01-23T13:48:00.696370Z","shell.execute_reply":"2022-01-23T13:48:25.950881Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"prev, dataframe = Perceptron.predict(test_X, test_y)\nhits = n_set = n_vers = n_virg = 0\nscore_set = score_vers = score_virg = 0\nfor j in range(len(test_y)):\n    if(test_y[j] == 0): n_set += 1\n    elif(test_y[j] == 1): n_vers += 1\n    elif(test_y[j] == 2): n_virg += 1\n        \nfor i in range(len(test_y)):\n    if test_y[i] == prev[i]: \n        hits += 1\n    if test_y[i] == prev[i] and test_y[i] == 0:\n        score_set += 1\n    elif test_y[i] == prev[i] and test_y[i] == 1:\n        score_vers += 1\n    elif test_y[i] == prev[i] and test_y[i] == 2:\n        score_virg += 1    \n         \nhits = (hits / len(test_y)) * 100\nfaults = 100 - hits","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:48:25.953747Z","iopub.execute_input":"2022-01-23T13:48:25.953976Z","iopub.status.idle":"2022-01-23T13:48:25.972707Z","shell.execute_reply.started":"2022-01-23T13:48:25.953930Z","shell.execute_reply":"2022-01-23T13:48:25.971760Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"dataframe","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:48:25.974083Z","iopub.execute_input":"2022-01-23T13:48:25.974393Z","iopub.status.idle":"2022-01-23T13:48:26.006755Z","shell.execute_reply.started":"2022-01-23T13:48:25.974339Z","shell.execute_reply":"2022-01-23T13:48:26.005301Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"graph_hits = []\nprint(\"Porcents :\",\"%.2f\"%(hits),\"% hits\",\"and\",\"%.2f\"%(faults),\"% faults\")\nprint(\"Total samples of test\",n_samples)\nprint(\"*Iris-Setosa:\",n_set,\"samples\")\nprint(\"*Iris-Versicolour:\",n_vers,\"samples\")\nprint(\"*Iris-Virginica:\",n_virg,\"samples\")\n\ngraph_hits.append(hits)\ngraph_hits.append(faults)\nlabels = 'Hits', 'Faults';\nsizes = [96.5, 3.3]\nexplode = (0, 0.14)\n\nfig1, ax1 = plt.subplots();\nax1.pie(graph_hits, explode=explode,colors=['green','red'],labels=labels, autopct='%1.1f%%',\nshadow=True, startangle=90)\nax1.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:48:26.008335Z","iopub.execute_input":"2022-01-23T13:48:26.008876Z","iopub.status.idle":"2022-01-23T13:48:26.128988Z","shell.execute_reply.started":"2022-01-23T13:48:26.008826Z","shell.execute_reply":"2022-01-23T13:48:26.127303Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"acc_set = (score_set/n_set)*100\nacc_vers = (score_vers/n_vers)*100\nacc_virg = (score_virg/n_virg)*100\nprint(\"- Acurracy Iris-Setosa:\",\"%.2f\"%acc_set, \"%\")\nprint(\"- Acurracy Iris-Versicolour:\",\"%.2f\"%acc_vers, \"%\")\nprint(\"- Acurracy Iris-Virginica:\",\"%.2f\"%acc_virg, \"%\")\nnames = [\"Setosa\",\"Versicolour\",\"Virginica\"]\nx1 = [2.0,4.0,6.0]\nfig, ax = plt.subplots()\nr1 = plt.bar(x1[0], acc_set,color='orange',label='Iris-Setosa')\nr2 = plt.bar(x1[1], acc_vers,color='green',label='Iris-Versicolour')\nr3 = plt.bar(x1[2], acc_virg,color='purple',label='Iris-Virginica')\nplt.ylabel('Scores %')\nplt.xticks(x1, names);plt.title('Scores by iris flowers - Multilayer Perceptron')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T13:48:26.130357Z","iopub.execute_input":"2022-01-23T13:48:26.130621Z","iopub.status.idle":"2022-01-23T13:48:26.315406Z","shell.execute_reply.started":"2022-01-23T13:48:26.130570Z","shell.execute_reply":"2022-01-23T13:48:26.314412Z"},"trusted":true},"execution_count":20,"outputs":[]}]}